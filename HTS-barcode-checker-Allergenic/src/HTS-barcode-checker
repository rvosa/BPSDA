#!/usr/bin/python

# Copyright (c) 2013, Naturalis Biodiversity Center and University of Applied
# Sciences Leiden. All rights reserved.
# 
# Redistribution and use in source and binary forms, with or without modification,
# are permitted provided that the following conditions are met:
# 
# *   Redistributions of source code must retain the above copyright notice, this
#     list of conditions and the following disclaimer.
# *   Redistributions in binary form must reproduce the above copyright notice,
#     this list of conditions and the following disclaimer in the documentation
#     and/or other materials provided with the distribution.
# *   Neither the name of the Naturalis Biodiversity Center, the University of
#     Applied Sciences Leiden nor the names of its contributors may be used to
#     endorse or promote products derived from this software without specific
#     prior written permission.
# 
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
# ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
# ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# these are all part of the standard library
import argparse, logging, os, sys, cgi, cgitb, StringIO, csv, time, collections, multiprocessing
from subprocess import call, Popen, PIPE

# The following modules are imported from BioPython
from Bio.Blast import NCBIWWW, NCBIXML
from Bio import SeqIO
from Bio import Entrez

# CHANGE ME:
# this location contains resources used both in command line and CGI mode:
# the default databases, static HTML, javascript, images
resources = '/Library/WebServer/CGI-Executables/resources'

# here we create a simple class so we can use the same
# symbol name regardless whether it was populated from CGI or argparse
class args(object):
	pass

def print_file_contents (filename,http_header):

	# prints the contents of provided file name to stdout, possibly 
	# prefixed with an HTTP header for HTML contents
	if http_header:
		print 'Content-type: text/html'
		print
	handle = open(filename, 'r')	
	print handle.read()

# running under CGI
if os.environ.get('GATEWAY_INTERFACE') is not None:

	# enable traces to browser
	cgitb.enable()
	
	# script was called without submitting the form (which would be method="post")
	if 'GET' in os.environ['REQUEST_METHOD']:
		print_file_contents(resources + '/static.html',True)
		sys.exit(0)
	else:
		# get the CGI form object
		form = cgi.FieldStorage()

		# populate the arguments object
		args.ah = True # write as HTML
		args.o  = '-' # write to stdout
		args.ad = True # no downloading when run as CGI		
		args.ba = form.getvalue('BLAST_algorithm')
		args.bd = form.getvalue('BLAST_database')
		args.hs = int(form.getvalue('hitlist_size'))
		args.lb = ( form.getvalue('localb') is not None )
		args.mb = ( form.getvalue('megablast') is not None )
		args.mi = int(form.getvalue('min_identity'))
		args.mc = int(form.getvalue('min_coverage'))
		args.me = float(form.getvalue('max_evalue'))
		args.cd = [ resources + '/allergen_db.csv' ]
		args.bl = resources + '/Blacklist.csv'
		args.i  = form['input_file'].file # handle to uploaded file		
		args.l  = 'critical' # be quiet	or we flood the server's error log
		args.lf = '' # no log file
	
else:
	# get the commandline arguments that specify the input fastafile and the output file
	parser = argparse.ArgumentParser(description = ('Identify a set of sequences and check if there are CITES species present'))
	parser.add_argument('-i', '--input_file', metavar='fasta file', dest='i', type=str, 
				help='input data in FASTA format, the number of sequences is limited to a 100 when running online BLAST searches.', default='', required=True)
	parser.add_argument('-o', '--output_file', metavar='output file', dest='o', type=str, 
				help='results file in TSV format. if "-" is provided, output is to STDOUT', default='-')
	parser.add_argument('-ba', '--BLAST_algorithm', metavar='algorithm', dest='ba', type=str, 
				help='BLAST algorithm to use (optional, default=blastn)', default='blastn')
	parser.add_argument('-bd', '--BLAST_database', metavar='database', dest='bd', type=str,
				help = 'BLAST database to use (optional, default=nt)', default = 'nt')
	parser.add_argument('-lb', '--local_blast', dest='lb', action='store_true', 
				help = 'blast using a local database (uses the ncbi-blast+ tool, this needs to installed separately)')
	parser.add_argument('-tf', '--taxon_file', metavar='taxon file', dest='tf', type=str,
				help = 'Taxon file containing the taxonid\'s + matching scientific names', default = '')
	parser.add_argument('-hs', '--hitlist_size', dest='hs', type=int,
				help = 'number of results BLAST will return (optional, default=10), the number of hits is limited to 20 when running online BLAST searches.', default = 10)
	parser.add_argument('-mb', '--megablast', dest='mb', action='store_true', 
				help = 'use megablast, can only be used in combination with blastn (optional)')
	parser.add_argument('-mi', '--min_identity', dest='mi', type=int, 
				help = 'lowest percentage identity for BLAST results to consider (optional, default=97)', default = 97)
	parser.add_argument('-mc', '--min_coverage', dest='mc', type=int, 
				help = 'minimal coverage for BLAST results in number of bases (optional, default=100)', default = 100)
	parser.add_argument('-me', '--max_evalue', dest='me', type=float, 
				help = 'threshold E-value for BLAST results (optional, default=0.05)', default = 0.05)
	parser.add_argument('-bl', '--blacklist', metavar='blacklist file', dest='bl', type=str, action='append',
				help = 'CSV file containing blacklisted genbank accession numbers (optional)', nargs='+') 
	parser.add_argument('-cd', '--allergen_db', metavar='allergen database file', dest='cd', type=str, action='append',
				help = 'one or more database (CSV) files with allergen-listed taxon identifiers', required=True, nargs='+')
	parser.add_argument('-fd', '--force_download', dest='fd', action='store_true',
				help = 'force update of the local allergen database (optional)')
	parser.add_argument('-ad', '--avoid_download', dest='ad', action='store_true',
				help = 'avoid updating the local allergen database (optional)')
	parser.add_argument('-ah', '--as_html', dest='ah', action='store_true', default = False,
				help = 'format output as HTML')
	parser.add_argument('-l', '--logging', metavar='log level', dest='l', type=str,
				help = 'set log level to: debug, info, warning (default) or critical', default='warning')
	parser.add_argument('-lf', '--log_file', metavar='log file', dest='lf', type=str,
				help = 'specifies a file to log to. if unset, logging is to STDERR', default='')
	args = parser.parse_args()


def sanitize_multiple_inputs(input_list):

	# remove list nesting on multiple input files
	if type(input_list[0]) == list:
		if len(input_list) > 1:
			return [item[0] for item in input_list]
		else:
			return input_list[0]
	else:
		return input_list


def blast_version ():
	
	# this function checks if the blast version available at the
	# path is version 2.2.28 or higher
	pipe = Popen(['blastn', '-version'], stdout=PIPE, stderr=PIPE)
	version = pipe.communicate()[0]
	try:
		version = int(version.split('\n')[0].split(' ')[1].replace('+','').replace('.',''))
		if version >= 2228:
			return 'pass'
		else:
			return 'low'
	except:
		return 'error'


def parse_taxon ():
	
	# open the taxonid file and return
	# a dictionary with the taxonid's as key
	# and the scientific names as values
	taxon_dic = {}
	for taxon in open(args.tf):
		taxon = taxon.strip().split('\t')
		taxon_dic[taxon[0]] = taxon[1]
	return taxon_dic


def get_blacklist ():
	
	# return a list containing the blacklisted genbank id's
	# the blacklist follows the following format:
	# genbank_id, description
	logging.debug('Trying to obtain genbank IDs from blacklist file: %s.' % args.bl)
	try:
		final_blacklist = []
		for blacklist_file in args.bl:		
			final_blacklist += [line.split(',')[0].split('.')[0] for line in open(blacklist_file,'r') if line[0] != '#']
		return list(set(final_blacklist))
	except:
		return []


def get_CITES ():
	
	# Open the Retrieve_Allergenic.py script to either check the status of the
	# user provided CITES database or obtain a new copy of the database
	logging.debug('Getting path to Retrieve_Allergenic.py script.')
	dir, file = os.path.split(os.path.realpath(sys.argv[0]))
	CITES_path = dir + '/Retrieve_Allergenic.py'
	logging.debug('Retrieve_Allergenic.py path set to: %s.' % CITES_path)

	if args.fd == True:
		path = call([CITES_path, '-db'] + args.cd + ['-f', '-l', args.l, '-lf', args.lf])
	else:
		path = call([CITES_path, '-db'] + args.cd + ['-l', args.l, '-lf', args.lf])


def get_CITES_dic ():
	
	# open the local CITES database, return a dictionary
	# containing the CITES information with the taxids as keys
	logging.debug('Parsing through list of CITES dictionaries.')

	CITES_dic = {}
	for path in args.cd:
		logging.debug('Reading CITES information from file: %s.' % path)
		with open(path, 'rb') as csvfile:
			reader = csv.reader(csvfile)		
			for line in reader:
				if line[0] != 'Date' and line[0][0] != '#':
					CITES_dic[line[0]] = line[1:]

	return CITES_dic

	
def obtain_tax (code):
	
	# try to obtain the taxon id
	taxon, count = ['unknown ID', 'unknown species'], 0
	while count < 3:
		try:
			# based on the genbank id the taxon id is retrieved from genbank
			Entrez.email = "HTS-barcode-checker@gmail.com"
			handle = Entrez.efetch(db="nucleotide", id= code, rettype="gb",retmode="text")
			record = SeqIO.read(handle, "gb")
	
			# parse through the features and grap the taxon_id
			sub = record.features
			db_xref = [code.split(':')[1] for code in sub[0].qualifiers['db_xref'] if 'taxon' in code][0]
			organism = sub[0].qualifiers['organism'][0]
			return [db_xref, organism]
		except:
			count += 1
	return taxon


def write_results (result, mode, tag, flag_cites):

	# ignore empty strings!
	if result != '':
	
		# format the result, either as html table row or as TSV row
		formatted = ''
		if args.ah:
		
			# create HTML table row
			formatted = '\t\t\t<tr'
			if flag_cites:
				formatted += ' class="cites"'
			formatted += '>\n'
			for i, item in enumerate(result):
				ncbi = 'http://ncbi.nlm.nih.gov/'
				
				# make clickable link to hit record
				if i == 2 and tag != 'th':
					item = '<a href="{}nuccore/{}">{}</a>'.format(ncbi,item,item)
					
				# make clickable link to taxonomy record
				if i == 7 and tag != 'th':
					item = '<a href="{}taxonomy/{}">{}</a>'.format(ncbi,item,item)
				template = '\t\t\t\t<{} class="col{}">{}</{}>\n'
				formatted += template.format(tag,i,item,tag)
			formatted += '\t\t\t</tr>\n'
			
			# write the results to stdout
			if args.o == '-':
				print(formatted + '\n')
	
			# write the results to the output file
			else:
				out_file = open(args.o, mode)
				out_file.write(formatted + '\n')
				out_file.close()			
			
		else:
			csvfile = sys.stdout
			if args.o != '-':
				csvfile = open(args.o, mode)
			writer = csv.writer(csvfile, delimiter = '\t',  quoting=csv.QUOTE_NONE, lineterminator='\n')
			writer.writerow(result)
	

def local_blast ():

	# BLAST the sequences against a local database using the ncbi-blast+ sofware package
	logging.debug('Starting local BLAST')
	temp_output = '{0}_temp-blast.tsv'.format(os.path.splitext(args.i)[0])
	cores = multiprocessing.cpu_count()

	# Use the selected BLAST algorithm
	if args.ba == 'blastn':
		BLAST_handle = Popen(['blastn', '-query', args.i, '-out', temp_output, '-db', args.bd,
					'-max_target_seqs', str(args.hs), '-num_threads', str(cores), '-outfmt',
					'6 qseqid sseqid stitle sgi sacc pident length qlen evalue bitscore staxids'],
					stdout=PIPE, stderr=PIPE)
	elif args.ba == 'blastp':
		BLAST_handle = Popen(['blastp', '-query', args.i, '-out', temp_output, '-db', args.bd,
					'-max_target_seqs', str(args.hs), '-num_threads', str(cores), '-outfmt',
					'6 qseqid sseqid stitle sgi sacc pident length qlen evalue bitscore staxids'],
					stdout=PIPE, stderr=PIPE)
	elif args.ba == 'blastx':
		BLAST_handle = Popen(['blastx', '-query', args.i, '-out', temp_output, '-db', args.bd,
					'-max_target_seqs', str(args.hs), '-num_threads', str(cores), '-outfmt',
					'6 qseqid sseqid stitle sgi sacc pident length qlen evalue bitscore staxids'],
					stdout=PIPE, stderr=PIPE)
	elif args.ba == 'tblastn':
		BLAST_handle = Popen(['tblastn', '-query', args.i, '-out', temp_output, '-db', args.bd,
					'-max_target_seqs', str(args.hs), '-num_threads', str(cores), '-outfmt',
					'6 qseqid sseqid stitle sgi sacc pident length qlen evalue bitscore staxids'],
					stdout=PIPE, stderr=PIPE)
	elif args.ba == 'tblastx':
		BLAST_handle = Popen(['tblastx', '-query', args.i, '-out', temp_output, '-db', args.bd,
					'-max_target_seqs', str(args.hs), '-num_threads', str(cores), '-outfmt',
					'6 qseqid sseqid stitle sgi sacc pident length qlen evalue bitscore staxids'],
					stdout=PIPE, stderr=PIPE)
	else:
		logging.critical('Invalid blast algorithm selected')
		sys.exit()

	logging.debug('Waiting for the local blast run to finish')
	logging.debug('BLAST message: {0}'.format(BLAST_handle.communicate()))

	# return the blast output file
	return temp_output
	

def parse_local_blast(CITES_dic, blacklist):

	# obtain the blast results
	temp_output = local_blast()
	
	# obtain the taxon dic if provided
	if args.tf != '':
		taxon_dic = parse_taxon()

	# parse through the output and format the data for filtering
	for line in open(temp_output):
		line = line.strip().split('\t')
		line[1:3] = [' '.join(line[1:3])]
		if ';' in line[-1]: line[-1] = line[-1].split(';')[0]
		
		# try to add the taxon id
		try:
			line += [taxon_dic[line[-1]]]
		except:
			line += ['']

		# send line away for filtering
		filter_hits(line, CITES_dic, blacklist)

	# remove the temp file
	os.remove(temp_output)


def online_blast (seq_list):

	# convert the sequences to a sequence file (stored in the
	# working memory)
	temp = StringIO.StringIO()
	SeqIO.write(seq_list, temp, 'fasta')	
	temp.seek(0,0)

	# BLAST the sequences online against a NCBI database
	logging.debug('BLASTING sequences agaist NCBI')
	result_handle = NCBIWWW.qblast(args.ba, args.bd, temp.read(), megablast=args.mb, hitlist_size=args.hs)

	# return the results handle with the blast results
	return result_handle


def parse_online_blast (seq_list, CITES_dic, blacklist):

	# get the result handle and set the taxon dic
	blast_handle, taxon_dic = online_blast(seq_list), {}

	# use the biopython xml parse module to get the results
	logging.debug('Parsing blast result XML file.')
	blast_list = [item for item in NCBIXML.parse(blast_handle)]

	# walk through the blast results and prepare them for filtering
	for blast_result in blast_list:
		for alignment in blast_result.alignments:
			for hsp in alignment.hsps:
				            		
				# calculate the %identity
				identity = float(hsp.identities/(len(hsp.match)*0.01))

				# grab the genbank number
				gb_num = alignment.title.split('|')[1:4:2]
				gb_num[1] = gb_num[1].split('.')[0]

				# get the taxon id based on the genbank identifier
				if gb_num[0] not in taxon_dic:
					taxon = obtain_tax(gb_num[0])
					taxon_dic[gb_num[0]] = taxon
				else:
					taxon = taxon_dic[gb_num[0]]

				# pull all the results together and sent them to the filter function
				filter_hits([str(blast_result.query), str(alignment.title), str(gb_num[0]),
						str(gb_num[1]),	str(identity), str(len(hsp.query)), str(blast_result.query_length),
						str(hsp.expect), str(hsp.bits), taxon[0], taxon[1]], CITES_dic, blacklist)


def filter_hits (blast, CITES_dic, blacklist):
	
	# filter the blast hits, based on the minimum
	# identity, minimum coverage, e-value and the user blacklist
	if float(blast[4]) >= args.mi and int(blast[5]) >= args.mc and float(blast[7]) <= args.me:
		if blast[2] not in blacklist and blast[3] not in blacklist:
			results, flag_cites = blast, False
			blast[6] = round((float(blast[5])/float(blast[6]))*100, 2)
			del results[3]

			# check if the taxon id of the blast hit
			# is present in the CITES_dic
			if blast[8] in CITES_dic:
				logging.debug('Appending CITES info to blast hit.')
				results += CITES_dic[blast[8]][1:]				
				flag_cites = True
			else:
				results += ['','','']
			
			# write the results
			write_results(results, 'a', 'td', flag_cites)


def parse_seq_file (CITES_dic, blacklist):

	# start the local or online blast
	if args.lb == True:
		logging.debug('Starting local blast functions.')
		parse_local_blast(CITES_dic, blacklist)
	else:
		# parse the fasta file
		logging.info('Reading user provided fasta file: %s.' % args.i)
		seq_list = [seq for seq in SeqIO.parse(args.i, 'fasta')]
	
		# check # sequences exceeds the 100 limit for online blasting
		if len(seq_list) > 100:
			logging.critical('To many sequences for online blasting, try using a sequence set'+
					' containing a maximum of a 100 sequences.')
			return

		logging.debug('Starting online blast functions.')
		parse_online_blast(seq_list, CITES_dic, blacklist)


def main ():

	# configure logging
	log_level  = getattr(logging, args.l.upper(), None)
	log_format = '%(funcName)s [%(lineno)d]: %(levelname)s: %(message)s'
	if not isinstance(log_level, int):
		raise ValueError('Invalid log level: %s' % loglevel)
		return	
	if args.lf == '':
		logging.basicConfig(format=log_format, level=log_level)
	else:
		logging.basicConfig(filename=args.lf, filemode='a', format=log_format, level=log_level)

	# Write input commands to log
	logging.debug(' '.join(sys.argv))

	# clean CITES lists and blacklist if applicable
	args.cd = sanitize_multiple_inputs(args.cd)
	if args.bl != None:
		args.bl = sanitize_multiple_inputs(args.bl)

	# if the users wants to run a local blast, check if the local blast version is high enough
	if args.lb == True:
		bv = blast_version()
		if bv == 'pass': logging.info('Local blast version is 2.2.28 or higher')
		elif bv == 'low':
			logging.critical('The local blast version is 2.2.27 or lower, update the blast+ software to a more' +
			' recent version or try using the online blast option.')
			return
		else:
			logging.critical('No local blast version is detected, make sure blast+ is installed correctly and' + 
			' available from the commandline.')
			return

	# check if the maximum number of blast hits exceeds 20 if the user wants
	# to blast the sequences online
	if args.lb == False and args.hs > 20:
		logging.critical('Maximum of online blast hits exceeds the limit of 20. Please lower the number blast hits.')
		return
	
	# Check if input fasta file and output file are provided
	if args.i == '':
		logging.critical('No fasta file or output file provided, see -help for details.')
		return

	# Check if there is a more recent CITES list online
	if args.ad != True:
		logging.info('Checking the status of the current CITES database.')
		get_CITES()

	# create a dictionary containing the local CITES set	
	logging.info('Reading the CITES database(s) from {0}'.format(args.cd))
	CITES_dic = get_CITES_dic()

	# create a list with the blacklisted genbank ids
	logging.info('Reading the user Taxon ID blacklist.')
	blacklist = get_blacklist()

input_	# create a blank result file and write the header
	if args.ah:
		print_file_contents(resources + '/header.html',True)
	header = [ 
		'Query ID',
		'Hit description',
		'GI',
		'% identity',
		'Hit length',
		'Hit % length',
		'E-value',
		'Bit score',
		'Taxon ID',
		'Species name',
		'NCBI taxon name'
	]
	write_results(header, 'w', 'th', False)

	# parse through the sequence file, blast all sequences and write the blast hits + CITES info
	logging.info('Processing the sequence file.')
	parse_seq_file(CITES_dic, blacklist)
	
	# write the HTML footer, if needed
	if args.ah:
		print_file_contents(resources + '/footer.html',False)

	logging.critical('Done. Results are written to the: ' + args.o + ' output file')


if __name__ == "__main__":
    main()

